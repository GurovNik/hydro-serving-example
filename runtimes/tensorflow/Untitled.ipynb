{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hydro-serving / Tensorflow\n",
    "\n",
    "## Proposal\n",
    "User trains model in genuine TF environment. We don't know where or how it's done. \n",
    "All we care about is a MetaGraphDef with serving Signatures.\n",
    "Current notebook exploits Tensorflow Serving techniquies and upgrades them.\n",
    "\n",
    "### Tensorflow Serving \n",
    "1. User trains model\n",
    "2. User defines one or more signatures for graph.\n",
    "3. User uses builder to export model.\n",
    "\n",
    "Signatures in Tensorflow are limited: classification, prediction and regression signatures with input/output conditions.\n",
    "\n",
    "### Hydro-serving\n",
    "1. User trains model\n",
    "2. User defines exactly one signature for graph.\n",
    "3. User uses builder to export model.\n",
    "\n",
    "As signature name user must use `tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY`.\n",
    "There are no restrictions for input/output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 171.385764254\n",
      "Epoch: 0002 cost= 42.497334743\n",
      "Epoch: 0003 cost= 26.916910444\n",
      "Epoch: 0004 cost= 18.939805758\n",
      "Epoch: 0005 cost= 13.740646046\n",
      "Epoch: 0006 cost= 10.257392485\n",
      "Epoch: 0007 cost= 7.555419819\n",
      "Epoch: 0008 cost= 5.697516615\n",
      "Epoch: 0009 cost= 4.262901346\n",
      "Epoch: 0010 cost= 3.197499346\n",
      "Epoch: 0011 cost= 2.392327013\n",
      "Epoch: 0012 cost= 1.852224836\n",
      "Epoch: 0013 cost= 1.482652549\n",
      "Epoch: 0014 cost= 1.131131825\n",
      "Epoch: 0015 cost= 0.929774977\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9484\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104edbf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Exporting trained model to /tmp/tf_model...\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'/tmp/tf_model/saved_model.pb'\n",
      "Export finished\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A Multilayer Perceptron implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits\n",
    "(http://yann.lecun.com/exdb/mnist/)\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input], name=\"x\")\n",
    "y = tf.placeholder(\"float\", [None, n_classes], name=\"y\")\n",
    "\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.add(tf.matmul(layer_2, weights['out']), biases['out'], name = \"out_classes\")\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "rand = tf.random_normal([2, 3], mean=-1, stddev=4)\n",
    "output = tf.argmax(pred,1)\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            feed = {x: batch_x, y: batch_y}\n",
    "            _, c = sess.run([optimizer, cost], feed_dict=feed)\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "    batch_x = mnist.train.next_batch(1)[0][0].reshape(1, 784)\n",
    "    \n",
    "    plt.imshow(batch_x.reshape(28, 28))\n",
    "    plt.show()\n",
    "    \n",
    "    bla = {\n",
    "         'x:0': batch_x\n",
    "    }\n",
    "    print(sess.run(output, feed_dict=bla))\n",
    "    \n",
    "    export_path = \"/tmp/tf_model\"\n",
    "    print('Exporting trained model to {0}...'.format(export_path))\n",
    "\n",
    "    shutil.rmtree(export_path)\n",
    "\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "\n",
    "    tensor_info_x = tf.saved_model.utils.build_tensor_info(x)\n",
    "    tensor_info_output = tf.saved_model.utils.build_tensor_info(output)\n",
    "    tensor_info_test = tf.saved_model.utils.build_tensor_info(rand)\n",
    "\n",
    "\n",
    "    \n",
    "    classification_signature = (\n",
    "      tf.saved_model.signature_def_utils.build_signature_def(\n",
    "          inputs={\n",
    "              'images': tensor_info_x\n",
    "          },\n",
    "          outputs={\n",
    "              'labels': tensor_info_output,\n",
    "              'labels2': tensor_info_output,\n",
    "              'random': tensor_info_test\n",
    "          },\n",
    "          method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME)\n",
    "    )\n",
    "    \n",
    "    legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "    builder.add_meta_graph_and_variables(\n",
    "      sess, [tf.saved_model.tag_constants.SERVING],\n",
    "      signature_def_map={\n",
    "          tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: classification_signature\n",
    "      },\n",
    "      legacy_init_op=legacy_init_op)\n",
    "    builder.save()\n",
    "    print('Export finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from b'/tmp/tf_model/variables/variables'\n",
      "['images']\n",
      "['labels', 'labels2', 'random']\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "{'x:0': matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)}\n",
      "[{'labels': 1, 'labels2': 1, 'random': [-3.8500704765319824, -0.3032868504524231, 1.7624523639678955], 'images': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.03529412,  0.66274512,  0.53725493,  0.04313726,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.50196081,\n",
      "        0.99607849,  0.99607849,  0.68627453,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.08627451,  0.95686281,  0.99607849,  0.99607849,\n",
      "        0.97647065,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.51764709,\n",
      "        0.99607849,  0.79215693,  0.96078438,  0.99607849,  0.32156864,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.20000002,  0.91372555,  0.99607849,  0.23529413,\n",
      "        0.58823532,  0.99607849,  0.37254903,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.29803923,\n",
      "        0.96470594,  0.60784316,  0.02352941,  0.58823532,  0.99607849,\n",
      "        0.37254903,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.20000002,  0.01568628,\n",
      "        0.        ,  0.58823532,  0.99607849,  0.37254903,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.58823532,\n",
      "        0.99607849,  0.37254903,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.58823532,  0.98431379,  0.08627451,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.58823532,  0.97647065,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.90588242,  0.97647065,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.98039222,  0.97647065,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.31764707,  0.99607849,\n",
      "        0.97647065,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.37647063,  0.99607849,  0.97647065,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.37647063,\n",
      "        0.99607849,  0.97647065,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.0509804 ,  0.72549021,  0.99607849,  0.85490203,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.42352945,\n",
      "        0.99607849,  0.99607849,  0.63921571,  0.        ,  0.11764707,\n",
      "        0.10196079,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.12156864,  0.96078438,  0.99607849,  0.99607849,\n",
      "        0.99215692,  0.74509805,  0.96078438,  0.92941183,  0.38039219,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.14509805,\n",
      "        0.96470594,  0.99607849,  0.99607849,  0.99607849,  0.99607849,\n",
      "        0.99607849,  0.99607849,  0.50588238,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.41960788,  0.45490199,\n",
      "        0.60392159,  0.60392159,  0.60392159,  0.93725497,  0.89019614,\n",
      "        0.15294118,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32), 'answer': array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), 'kek': 1}, {'labels': 7, 'labels2': 7, 'random': [-1.7141374349594116, 0.21255457401275635, 3.45231294631958], 'images': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.05882353,  0.85490203,\n",
      "        0.62352943,  0.25882354,  0.        ,  0.        ,  0.04705883,\n",
      "        0.24705884,  0.24705884,  0.24705884,  0.24705884,  0.24705884,\n",
      "        0.24705884,  0.24705884,  0.18431373,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.11764707,  0.92549026,  0.99607849,  0.92156869,\n",
      "        0.8705883 ,  0.8705883 ,  0.89411771,  0.99607849,  0.99607849,\n",
      "        0.99607849,  0.99607849,  0.99607849,  0.99607849,  0.99607849,\n",
      "        0.86274517,  0.05490196,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.22352943,  0.53333336,  0.71372551,  0.99607849,  0.99607849,\n",
      "        0.99607849,  0.99607849,  0.99607849,  0.80000007,  0.63921571,\n",
      "        0.63921571,  0.96470594,  0.99607849,  0.80392164,  0.03137255,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.00392157,  0.01568628,  0.01568628,  0.01568628,  0.01568628,\n",
      "        0.01568628,  0.00784314,  0.        ,  0.36862746,  0.99607849,\n",
      "        0.99215692,  0.28235295,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.10588236,  0.94901967,  0.98431379,  0.60000002,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.05882353,  0.86274517,  0.99607849,\n",
      "        0.57254905,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.39607847,  0.99607849,  0.93725497,  0.23137257,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.00784314,  0.19215688,  0.89411771,  0.95294124,\n",
      "        0.24705884,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.18039216,\n",
      "        0.99607849,  0.9450981 ,  0.25490198,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.25490198,  0.96862751,  0.99607849,  0.25882354,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.14117648,  0.89803928,\n",
      "        0.99607849,  0.56862748,  0.01568628,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.02352941,  0.67058825,  0.99607849,  0.68235296,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.49411768,  0.99607849,\n",
      "        0.89411771,  0.1137255 ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.32549021,  0.96470594,  0.98431379,  0.35294119,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.09803922,  0.84705889,  0.99607849,\n",
      "        0.56862748,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.07450981,\n",
      "        0.72549021,  0.99607849,  0.52549022,  0.02745098,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.00784314,  0.76862752,  0.99607849,  0.67843139,\n",
      "        0.03921569,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.71372551,\n",
      "        0.99607849,  0.90588242,  0.02745098,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.01568628,  0.54509807,  0.99607849,  0.9333334 ,  0.28627452,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.1137255 ,  0.99607849,\n",
      "        0.99607849,  0.52549022,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32), 'answer': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]), 'kek': 2}]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "in_x, in_y = mnist.train.next_batch(1)\n",
    "in2_x, in2_y = mnist.train.next_batch(1)\n",
    "input_data = [\n",
    "    {\n",
    "        'images': in_x[0],\n",
    "        'answer': in_y[0],\n",
    "        \"kek\":1\n",
    "    },\n",
    "    {\n",
    "        'images': in2_x[0],\n",
    "        'answer': in2_y[0],\n",
    "        \"kek\":2\n",
    "    }\n",
    "]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    meta_graph = tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_path)\n",
    "    signature = meta_graph.signature_def['serving_default']\n",
    "    inputs = list(signature.inputs._values.keys())\n",
    "    outputs = list(signature.outputs._values.keys())\n",
    "    print(inputs)\n",
    "    print(outputs)\n",
    "    \n",
    "    input_tensors = {x: sess.graph.get_tensor_by_name(signature.inputs[x].name) for x in inputs}\n",
    "    output_tensors = {x: sess.graph.get_tensor_by_name(signature.outputs[x].name) for x in outputs}\n",
    "\n",
    "    \n",
    "    dicts = dict(zip(input_data[0], zip(*[d.values() for d in input_data])))\n",
    "    \n",
    "    feed_dict = {v.name: concatListOfArrs(list(dicts[k])) for (k, v) in input_tensors.items() }\n",
    "    \n",
    "    print(feed_dict)\n",
    "    \n",
    "#     plt.imshow(bla['x:0'].reshape(28, 28))\n",
    "#     plt.show()\n",
    "    \n",
    "    result = sess.run(output_tensors, feed_dict)\n",
    "    \n",
    "    result = {k: v.tolist() if type(v) is np.ndarray else v for k, v in result.items() }\n",
    "    \n",
    "    res = dict(list(result.items()) + list(dicts.items()))\n",
    "    res_list = [dict(zip(res,t)) for t in zip(*res.values())]\n",
    "    \n",
    "    print(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_x, in_y = mnist.train.next_batch(1)\n",
    "in2_x, in2_y = mnist.train.next_batch(1)\n",
    "input_data = [\n",
    "    {\n",
    "        'images': in_x[0],\n",
    "        'answer': in_y[0],\n",
    "        \"kek\":1\n",
    "    },\n",
    "    {\n",
    "        'images': in2_x[0],\n",
    "        'answer': in2_y[0],\n",
    "        \"kek\":2\n",
    "    }\n",
    "]\n",
    "dicts = dict(zip(input_data[0], zip(*[d.values() for d in input_data])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "feed = {x: batch_x, y: batch_y}\n",
    "print(type(feed[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concatListOfArrs(lst):\n",
    "    print(type(lst))\n",
    "    print(type(lst[0]))    \n",
    "    return np.matrix(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [1, 2, 3, 4, 5], 'b': [3, 4, 1, 4, 5]}\n"
     ]
    }
   ],
   "source": [
    "a = {'a': [1,2,3,4,5]}\n",
    "b = {'b': [3,4,1,4,5]}\n",
    "\n",
    "c = dict(list(a.items()) + list(b.items()))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47058827, 0.99215692, 0.99215692, 0.39607847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.074509807, 0.88235301, 0.98823535, 0.89019614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25882354, 0.98823535, 0.98823535, 0.4039216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5529412, 0.98823535, 0.98823535, 0.10980393, 0.0, 0.0, 0.0, 0.0, 0.44705886, 0.34509805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.60392159, 0.99215692, 0.99215692, 0.10980393, 0.0, 0.0, 0.0, 0.44705886, 1.0, 0.77254909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99215692, 0.98823535, 0.76862752, 0.035294119, 0.0, 0.0, 0.0, 0.73725492, 0.99215692, 0.76862752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14901961, 0.99215692, 0.98823535, 0.3137255, 0.0, 0.0, 0.0, 0.0, 0.88235301, 0.99215692, 0.42745101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.63921571, 0.99215692, 0.79215693, 0.023529414, 0.0, 0.0, 0.0, 0.29803923, 0.97647065, 0.99215692, 0.32941177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.88627458, 0.99607849, 0.77254909, 0.0, 0.0, 0.0, 0.027450982, 0.60392159, 0.99215692, 0.93725497, 0.14901961, 0.0, 0.0, 0.36078432, 0.57254905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.074509807, 0.90588242, 0.99215692, 0.47450984, 0.0, 0.0, 0.0, 0.32156864, 0.98823535, 0.98823535, 0.58823532, 0.0, 0.074509807, 0.6156863, 0.84705889, 0.76862752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48235297, 0.98823535, 0.99215692, 0.84313732, 0.77254909, 0.77254909, 0.77647066, 0.91764712, 0.98823535, 0.98823535, 0.87450987, 0.77254909, 0.84313732, 0.98823535, 0.99215692, 0.76862752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000002, 0.96470594, 0.98823535, 0.99215692, 0.98823535, 0.98823535, 0.98823535, 0.99215692, 0.98823535, 0.98823535, 0.98823535, 0.99215692, 0.98823535, 0.98823535, 0.98823535, 0.50196081, 0.086274512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22352943, 0.99215692, 0.9450981, 0.63921571, 0.44313729, 0.44313729, 0.83529419, 0.99607849, 0.99215692, 0.99215692, 0.89411771, 0.44705886, 0.44313729, 0.098039225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.074509807, 0.32941177, 0.18431373, 0.0, 0.0, 0.0, 0.20000002, 0.99215692, 0.98823535, 0.76862752, 0.035294119, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.88235301, 0.99215692, 0.91372555, 0.24313727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29803923, 0.97647065, 0.99215692, 0.76862752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027450982, 0.80000007, 0.99215692, 0.88627458, 0.14901961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22352943, 0.98823535, 0.98823535, 0.44313729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56470591, 0.98823535, 0.98823535, 0.098039225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4666667, 0.98823535, 0.40000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "a, b = mnist.train.next_batch(1)\n",
    "print(list(a[0]))\n",
    "print(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
